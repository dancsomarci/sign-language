{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fe38c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install mediapipe==0.9.0.1\n",
    "!pip install protobuf==3.20.*\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e090ade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import mediapipe as mp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "from skimage.transform import resize\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "# For extraction and drawing\n",
    "import cv2\n",
    "from itertools import chain\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e404aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b96aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pose coordinates for hand movement.\n",
    "# LPOSE = [13, 15, 17, 19, 21]\n",
    "# RPOSE = [14, 16, 18, 20, 22]\n",
    "# POSE = LPOSE + RPOSE\n",
    "\n",
    "# X = [f'x_right_hand_{i}' for i in range(21)] + [f'x_left_hand_{i}' for i in range(21)] + [f'x_pose_{i}' for i in POSE]\n",
    "# Y = [f'y_right_hand_{i}' for i in range(21)] + [f'y_left_hand_{i}' for i in range(21)] + [f'y_pose_{i}' for i in POSE]\n",
    "# Z = [f'z_right_hand_{i}' for i in range(21)] + [f'z_left_hand_{i}' for i in range(21)] + [f'z_pose_{i}' for i in POSE]\n",
    "\n",
    "# FEATURE_COLUMNS = X + Y + Z\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "# Pose coordinates for hand movement.\n",
    "LPOSE = [13, 15, 17, 19, 21]\n",
    "RPOSE = [14, 16, 18, 20, 22]\n",
    "POSE = LPOSE + RPOSE\n",
    "\n",
    "def extract_from_result(res):\n",
    "    # Extract specific pose landmarks if available\n",
    "    px = []\n",
    "    py = []\n",
    "    pz = []\n",
    "    if res.pose_landmarks:\n",
    "        for i in POSE:\n",
    "            lm = res.pose_landmarks.landmark[i]\n",
    "            px.append(lm.x)\n",
    "            py.append(lm.y)\n",
    "            pz.append(lm.z)\n",
    "    else:\n",
    "        px = [0.0]*len(POSE)\n",
    "        py = [0.0]*len(POSE)\n",
    "        pz = [0.0]*len(POSE)\n",
    "\n",
    "    # Extract left hand landmarks if available\n",
    "    lx = []\n",
    "    ly = []\n",
    "    lz = []\n",
    "    if res.left_hand_landmarks:\n",
    "        for lm in res.left_hand_landmarks.landmark:\n",
    "            lx.append(lm.x)\n",
    "            ly.append(lm.y)\n",
    "            lz.append(lm.z)\n",
    "    else:\n",
    "        lx = [0.0]*21\n",
    "        ly = [0.0]*21\n",
    "        lz = [0.0]*21\n",
    "\n",
    "    # Extract right hand landmarks if available\n",
    "    rx = []\n",
    "    ry = []\n",
    "    rz = []\n",
    "    if res.right_hand_landmarks:\n",
    "        for lm in res.right_hand_landmarks.landmark:\n",
    "            rx.append(lm.x)\n",
    "            ry.append(lm.y)\n",
    "            rz.append(lm.z)\n",
    "    else:\n",
    "        rx = [0.0]*21\n",
    "        ry = [0.0]*21\n",
    "        rz = [0.0]*21\n",
    "\n",
    "    return list(chain(rx, lx, px, ry, ly, py, rz, lz, pz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a7c9750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_video(path_to_video: str):\n",
    "    data = []\n",
    "    video = cv2.VideoCapture(path_to_video)\n",
    "    try:\n",
    "        with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "            while True:\n",
    "                _, frame = video.read()\n",
    "                if frame is None:\n",
    "                    break\n",
    "\n",
    "                frame.flags.writeable = False\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = holistic.process(frame)\n",
    "                data.append(extract_from_result(results))\n",
    "    finally:\n",
    "        video.release()\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "786c5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "\n",
    "MAX_LEN = 15\n",
    "\n",
    "def preprocess_data(data: list):\n",
    "    sliding_window = deque(maxlen=MAX_LEN)\n",
    "\n",
    "    sequences = []\n",
    "    for pose in data:\n",
    "        sliding_window.append(pose)\n",
    "        if len(sliding_window) == MAX_LEN:\n",
    "            seq = deepcopy(list(sliding_window))\n",
    "            sequences.append(seq)\n",
    "        \n",
    "    return  sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a899f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468a283b07a54867a9e03fea335a5580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da547185fe94bc7b4a26a0ff33bd5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in tqdm(range(1, 6)):\n",
    "    data = load_data_from_video(f\"signing samples/{i}.mp4\")\n",
    "    d = preprocess_data(data)\n",
    "    x.extend(d)\n",
    "    y.extend([1]*len(d))\n",
    "    \n",
    "for i in tqdm(range(1, 10)):\n",
    "    data = load_data_from_video(f\"not signing samples/{i}.mp4\")\n",
    "    d = preprocess_data(data)\n",
    "    x.extend(d)\n",
    "    y.extend([0]*len(d))\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "perm = np.random.permutation(len(x))\n",
    "\n",
    "x = x[perm]\n",
    "y = y[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac8c00dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19754, 15, 156)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e6c1769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 1)                 632       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 636\n",
      "Trainable params: 636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(1, input_shape=(MAX_LEN, 156)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c90ce0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "433/433 [==============================] - 3s 5ms/step - loss: 0.6095 - accuracy: 0.7292 - val_loss: 0.5027 - val_accuracy: 0.9450\n",
      "Epoch 2/10\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.4310 - accuracy: 0.9531 - val_loss: 0.3740 - val_accuracy: 0.9523\n",
      "Epoch 3/10\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.3281 - accuracy: 0.9599 - val_loss: 0.2925 - val_accuracy: 0.9605\n",
      "Epoch 4/10\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.2598 - accuracy: 0.9658 - val_loss: 0.2405 - val_accuracy: 0.9629\n",
      "Epoch 5/10\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.2151 - accuracy: 0.9686 - val_loss: 0.2034 - val_accuracy: 0.9659\n",
      "Epoch 6/10\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.1833 - accuracy: 0.9706 - val_loss: 0.1755 - val_accuracy: 0.9678\n",
      "Epoch 7/10\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.1600 - accuracy: 0.9722 - val_loss: 0.1619 - val_accuracy: 0.9671\n",
      "Epoch 8/10\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.1464 - accuracy: 0.9722 - val_loss: 0.1426 - val_accuracy: 0.9708\n",
      "Epoch 9/10\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.1300 - accuracy: 0.9743 - val_loss: 0.1425 - val_accuracy: 0.9678\n",
      "Epoch 10/10\n",
      "433/433 [==============================] - 2s 4ms/step - loss: 0.1208 - accuracy: 0.9754 - val_loss: 0.1248 - val_accuracy: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x266884e4820>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, validation_split=0.3, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bc1dd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"detect_signing.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08a72607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618/618 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2eed0841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9953"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.argmax(preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a59f8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9906"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3741cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1932,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7884533a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
