-meggyűlt a bajom a modellek kezelésével (lementésével -> sad)

Fingerspelling:
	-előző héthez képest bug felfedezése: most common helyett 70% os többség kell
	+predikciós ablak mérete legyen kisebb (50->15)
	= nagyon jó eredmények magabiztosan találja meg a karaktereket kivéve, ha az illető nem jelel

	solution:
		két ötlet: 
			másik modell ami detektálja mikor jelel az ember
				- nehéz elég robosztus adathalmazt felépíteni (arra tanul rá a modell, hogy felemelem a kezem, de bizonyos helyzetekben nem magabiztos)
			a modell visszaad konfidenciát is, vagy
				-mentéses mizéria miatt nem tudtam kipróbálni
	
	-előző héthez képest másik bug: nem az egész contextet adtam neki oda a predikcióhoz, hanem csak az utolsó elemet
		-mentéses mizéria miatt késik az eredmény

	-találtam egy google-ös google collab tutorialt, ahol nagyon részletesen el van magyarázva egy basic transformer kialakítása
		-mostmár tényleg mélyen értem a működést
		-eddig a kaggle competition egyik pinelt notebookját követtem, amiben voltak hibák pl.: random errorok mentéskor, szekvenciák feleslegesen hosszúra voltak padelve
	
	-kaggle ösben találtam egy másik adathalmazt is, amiben csak egyszerű szövegek vannak (nem linkek meg url-ek stb)
		-tanításhoz úgy tűnik rosszabb, de összevonva vagy azt használva teszt adatnak lehet jó lenne (bár picit rosszabb minőségű)

	-videóból predikciónál, a videó ha végetér ki kell üríteni a fifót, mert néha beragad az utolsó karakter

-singning detection model (kis adathalmazt raktam össze)
	-nagyon primitív módon megmondja mikor jelel az ember
	-nem tökéletes lehetne rajta javítani, de kb egy heurisztikát tanul meg hogy ha flemeli az ember a kezét akkor jelel vagy valami hasonló, de adtam neki olyan adatot is amikor fent van a kéz de nem jelel senki
	-bizonyításra vár a működése


-gpt prompt a bizonytalanság megfejtésére
	zero-shot learning nem volt az igazi, de few shot learninggel ment a dolog
		Now lets switch to fingerspelling. I have a model that detects fingerspelling but is not great. Can you correct the mistakes and only provide a valid translation? The text I will give you contains almost all characters but sometimes one is missing. There are also cases where the start or the end of the word is padded with nonsense characters.
		examples:
		jattiger -> tiger
		bearueu -> bear
		www.hal -> whale

-gpt prompttal elég jól lehet gloss-t fordítani (szórendeket elég jól cseréli meg névelőket stb bepótol)

-hogyan lehetne jól tesztelni? hogy szokták ilyen köröben???

-cím ötlet: 
Olyan irányba vinném el az egészet, hogy ez inkább modelles tdk mint aplikációs, de azért az is van benne

Jelnyelv fordítása, hallássérült jelelők támogatására,
póz approximációs módszerek, szekvencia feldolgozásra alkalmas MI algoritmusok és
nagy nyelvi modellekre épülő eredmény korrekció felhasználásával

-gondok voltak a gépemmel, szóval kamerás dolgot még nem sikerült működsére bírni

